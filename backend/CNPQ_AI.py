"""
Script para raspagem de chamadas p√∫blicas do CNPq
Executa manualmente e salva resultado em JSON
Foco: Extrair links dos bot√µes 'Chamada' dentro de divs com classe 'links-normas'
Integra√ß√£o com OpenAI e ChromaDB para extra√ß√£o de vari√°veis
"""

import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime
from pathlib import Path
import pdfplumber
from io import BytesIO
import os
import argparse
from dotenv import load_dotenv
from openai import OpenAI
import chromadb
from chromadb.utils import embedding_functions

# Carregar vari√°veis de ambiente do arquivo .env
load_dotenv()


# =====================================================================
# CONFIG
# =====================================================================
# Obt√©m a chave da API do OpenAI das vari√°veis de ambiente
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
print(f"[DEBUG] OPENAI_API_KEY encontrada: {'Sim' if OPENAI_API_KEY else 'N√£o'}")

# Se a chave n√£o estiver definida, tente usar a chave diretamente do arquivo .env
if not OPENAI_API_KEY:
    try:
        with open(os.path.join(os.path.dirname(__file__), '.env'), 'r') as f:
            for line in f:
                if line.startswith('OPENAI_API_KEY='):
                    OPENAI_API_KEY = line.strip().split('=', 1)[1].strip('"\'')
                    print(f"[DEBUG] OPENAI_API_KEY carregada diretamente do arquivo .env")
                    break
    except Exception as e:
        print(f"[DEBUG] Erro ao ler arquivo .env: {e}")

# Inicializar cliente OpenAI
if OPENAI_API_KEY:
    client = OpenAI(api_key=OPENAI_API_KEY)
    print("‚úÖ Cliente OpenAI inicializado com sucesso")
else:
    print("‚ùå ERRO: OPENAI_API_KEY n√£o encontrada. Configure a vari√°vel de ambiente ou o arquivo .env")
    exit(1)

# Configura√ß√£o do ChromaDB (opcional)
USE_CHROMA = False  # Padr√£o: desativado (pode ser ativado via linha de comando)
chroma_client = None
collection = None

# Configura√ß√£o para o ChromaDB dockerizado
CHROMA_HOST = "localhost"  # Use "chroma" se estiver rodando dentro do mesmo docker-compose
CHROMA_PORT = 8001  # Porta mapeada no container Docker

# Processar argumentos de linha de comando
def parse_args():
    parser = argparse.ArgumentParser(description="Raspador de chamadas p√∫blicas do CNPq com extra√ß√£o de vari√°veis")
    parser.add_argument("--chroma", action="store_true", help="Ativar integra√ß√£o com ChromaDB")
    parser.add_argument("--chroma-host", type=str, default="localhost", help="Host do ChromaDB (padr√£o: localhost)")
    parser.add_argument("--chroma-port", type=int, default=8001, help="Porta do ChromaDB (padr√£o: 8001)")
    parser.add_argument("--limite", type=int, default=None, help="Limite de chamadas para processar")
    return parser.parse_args()

if USE_CHROMA:
    try:
        # Tentar conex√£o com retry para garantir que o servi√ßo est√° dispon√≠vel
        max_retries = 3
        retry_delay = 2  # segundos
        
        for attempt in range(1, max_retries + 1):
            try:
                print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Tentativa {attempt}/{max_retries} de conex√£o ao ChromaDB...")
                chroma_client = chromadb.HttpClient(host=CHROMA_HOST, port=CHROMA_PORT)
                
                # Testar conex√£o
                collections = chroma_client.list_collections()
                print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ‚úÖ Conex√£o com ChromaDB estabelecida. Collections dispon√≠veis: {len(collections)}")
                
                # Configurar embedding function
                embedding_fn = embedding_functions.OpenAIEmbeddingFunction(
                    api_key=OPENAI_API_KEY,
                    model_name="text-embedding-3-small"
                )
                
                # Criar ou obter cole√ß√£o
                collection = chroma_client.get_or_create_collection(
                    name="editais_cnpq",
                    embedding_function=embedding_fn
                )
                print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ‚úÖ Cole√ß√£o 'editais_cnpq' pronta para uso.")
                break
            except Exception as retry_e:
                print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Tentativa {attempt} falhou: {retry_e}")
                if attempt < max_retries:
                    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Aguardando {retry_delay}s antes da pr√≥xima tentativa...")
                    import time
                    time.sleep(retry_delay)
                else:
                    raise
    except Exception as e:
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ‚ùå ERRO ao conectar com ChromaDB ap√≥s {max_retries} tentativas: {e}")
        print("Continuando sem ChromaDB...")
        USE_CHROMA = False


# =====================================================================
# FUN√á√ïES DE SUPORTE
# =====================================================================
def chunk_texto(texto, tamanho_chunk=1200, sobreposicao=200):
    """
    Divide o texto em peda√ßos (chunks) para enviar √† LLM e indexar no ChromaDB.
    """
    chunks = []
    inicio = 0
    while inicio < len(texto):
        fim = inicio + tamanho_chunk
        chunk = texto[inicio:fim]
        chunks.append(chunk.strip())
        inicio += tamanho_chunk - sobreposicao
    return chunks


def extrair_variaveis_llm(texto, link):
    """
    Envia os chunks do texto para a LLM e consolida as vari√°veis em JSON.
    """
    chunks = chunk_texto(texto)
    resultados = []

    for i, chunk in enumerate(chunks, 1):
        prompt = f"""
        Voc√™ √© um extrator de informa√ß√µes de editais.
        Extraia os seguintes campos em formato JSON v√°lido:

        {{
          "apelido_edital": "STRING",
          "financiador_1": "STRING",
          "financiador_2": "STRING",
          "area_foco": "STRING",
          "tipo_proponente": "STRING",
          "empresas_que_podem_submeter": "STRING",
          "duracao_min_meses": "NUMBER",
          "duracao_max_meses": "NUMBER",
          "valor_min_R$": "NUMBER",
          "valor_max_R$": "NUMBER",
          "tipo_recurso": "STRING",
          "recepcao_recursos": "STRING",
          "custeio": "BOOLEAN",
          "capital": "BOOLEAN",
          "contrapartida_min_%": "NUMBER",
          "contrapartida_max_%": "NUMBER",
          "tipo_contrapartida": "STRING",
          "data_inicial_submissao": "YYYY-MM-DD",
          "data_final_submissao": "YYYY-MM-DD",
          "data_resultado": "YYYY-MM-DD",
          "descricao_completa": "STRING",
          "origem": "STRING",
          "link": "STRING",
          "observacoes": "STRING"
        }}

        Se algum campo n√£o estiver presente neste trecho, preencha com null.

        Texto do edital (chunk {i}/{len(chunks)}):
        {chunk}
        """

        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Processando chunk {i}/{len(chunks)} do edital {link}")
        
        try:
            resp = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0
            )

            try:
                dados = json.loads(resp.choices[0].message.content)
            except:
                dados = {"erro": "resposta inv√°lida", "raw": resp.choices[0].message.content}

            dados["link"] = link
            dados["chunk_index"] = i
            resultados.append(dados)

            # Inserir no ChromaDB (se estiver ativado)
            if USE_CHROMA and collection:
                try:
                    # Gerar ID √∫nico para o documento
                    timestamp = datetime.now().timestamp()
                    doc_id = f"{link.replace('http://', '').replace('https://', '').replace('/', '_')}_chunk_{i}_{timestamp}".replace(".", "_")
                    
                    # Preparar metadados estruturados
                    metadata = {
                        "link": link,
                        "chunk_index": i,
                        "total_chunks": len(chunks),
                        "timestamp": timestamp,
                        "caracteres": len(chunk),
                        "processado_em": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    }
                    
                    # Adicionar vari√°veis extra√≠das (se n√£o for erro)
                    if not dados.get("erro"):
                        # Converter vari√°veis para string JSON para armazenamento
                        metadata["variaveis_extraidas"] = json.dumps(dados)
                        
                        # Adicionar campos espec√≠ficos para facilitar buscas
                        for campo in ["apelido_edital", "financiador_1", "area_foco", "tipo_proponente", 
                                      "valor_min_R$", "valor_max_R$", "data_final_submissao"]:
                            if dados.get(campo):
                                metadata[f"var_{campo}"] = str(dados.get(campo))
                    else:
                        metadata["erro_extracao"] = dados.get("erro")
                    
                    # Adicionar ao ChromaDB
                    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] üíæ Salvando chunk {i} no ChromaDB...")
                    collection.add(
                        documents=[chunk],
                        metadatas=[metadata],
                        ids=[doc_id]
                    )
                    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ‚úÖ Chunk {i} processado e adicionado ao ChromaDB com sucesso")
                except Exception as e:
                    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ‚ùå ERRO ao adicionar ao ChromaDB: {e}")
                    print("Continuando sem salvar no ChromaDB...")
            else:
                print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ‚úÖ Chunk {i} processado (ChromaDB desativado)")
            
        except Exception as e:
            print(f"‚ùå Erro ao processar chunk {i}: {str(e)}")
            resultados.append({"erro": str(e), "link": link, "chunk_index": i})

    return resultados


# =====================================================================
# ETAPA 1: RASPAGEM DO CNPQ
# =====================================================================
def raspar_cnpq():
    """
    Faz scraping das chamadas p√∫blicas abertas do CNPq
    Foco em extrair os bot√µes 'Chamada' dentro de divs com classe 'links-normas'
    Retorna os dados estruturados
    """
    url = "http://memoria2.cnpq.br/web/guest/chamadas-publicas?p_p_id=resultadosportlet_WAR_resultadoscnpqportlet_INSTANCE_0ZaM&filtro=abertas/"
    
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Iniciando raspagem do CNPq...")
    print(f"URL: {url}")
    
    try:
        # Fazer requisi√ß√£o GET
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Requisi√ß√£o bem-sucedida! Status: {response.status_code}")
        
        # Parse do HTML
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # Extrair chamadas p√∫blicas
        chamadas = []
        
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Processando conte√∫do...")
        
        # ESTRAT√âGIA PRINCIPAL: Buscar bot√µes 'Chamada' dentro de divs com classe 'links-normas'
        botoes_chamada = soup.find_all('div', class_='links-normas')
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Encontrados {len(botoes_chamada)} divs 'links-normas'")
        
        for idx, div_links in enumerate(botoes_chamada, 1):
            # Buscar o link do bot√£o 'Chamada' com classe 'btn'
            link_chamada = div_links.find('a', class_='btn', href=True)
            
            if link_chamada:
                href = link_chamada.get('href', '')
                
                chamada_info = {
                    'id': idx,
                    'link_chamada': href
                }
                
                chamadas.append(chamada_info)
                print(f"  ‚úì Chamada {idx}: {href}")
        
        # ESTRAT√âGIA FALLBACK: Se n√£o encontrou nada, buscar links que apontam para resultado.cnpq.br
        if len(chamadas) == 0:
            print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Usando estrat√©gia alternativa (fallback)...")
            links_resultado = soup.find_all('a', href=lambda x: x and 'resultado.cnpq.br' in x)
            
            for idx, link in enumerate(links_resultado, 1):
                href = link.get('href', '')
                
                chamada_info = {
                    'id': idx,
                    'link_chamada': href
                }
                chamadas.append(chamada_info)
                print(f"  ‚úì Chamada {idx} (fallback): {href}")
        
        # Estrutura final dos dados
        dados_estruturados = {
            'metadata': {
                'fonte': 'CNPq - Chamadas P√∫blicas Abertas',
                'url': url,
                'data_raspagem': datetime.now().isoformat(),
                'total_chamadas_encontradas': len(chamadas),
                'estrategia_usada': 'links-normas' if len(botoes_chamada) > 0 else 'fallback',
                'status': 'sucesso'
            },
            'chamadas': chamadas
        }
        
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Raspagem conclu√≠da!")
        print(f"Total de chamadas encontradas: {len(chamadas)}")
        
        return dados_estruturados
        
    except requests.exceptions.RequestException as e:
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ERRO na requisi√ß√£o: {e}")
        return {
            'metadata': {
                'fonte': 'CNPq - Chamadas P√∫blicas Abertas',
                'url': url,
                'data_raspagem': datetime.now().isoformat(),
                'status': 'erro',
                'erro': str(e)
            },
            'chamadas': []
        }
    except Exception as e:
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ERRO no processamento: {e}")
        return {
            'metadata': {
                'fonte': 'CNPq - Chamadas P√∫blicas Abertas',
                'url': url,
                'data_raspagem': datetime.now().isoformat(),
                'status': 'erro',
                'erro': str(e)
            },
            'chamadas': []
        }


def buscar_conteudo_chamada(link_chamada):
    """
    Faz GET em um link espec√≠fico de chamada e retorna o conte√∫do
    Detecta se √© PDF e extrai o texto
    Retorna a vari√°vel conteudo_chamada
    """
    print(f"\n[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Buscando conte√∫do da chamada...")
    print(f"Link: {link_chamada}")
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(link_chamada, headers=headers, timeout=30)
        response.raise_for_status()
        
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Requisi√ß√£o bem-sucedida! Status: {response.status_code}")
        
        # Verificar se √© PDF pelo Content-Type
        content_type = response.headers.get('Content-Type', '')
        
        if 'application/pdf' in content_type or link_chamada.lower().endswith('.pdf'):
            print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Detectado arquivo PDF. Extraindo texto...")
            
            # Extrair texto do PDF usando pdfplumber
            pdf_bytes = BytesIO(response.content)
            texto_completo = ''
            total_paginas = 0
            
            with pdfplumber.open(pdf_bytes) as pdf:
                total_paginas = len(pdf.pages)
                print(f"   Total de p√°ginas: {total_paginas}")
                
                for pagina_num, pagina in enumerate(pdf.pages, 1):
                    texto_pagina = pagina.extract_text()
                    if texto_pagina:
                        texto_completo += f"\n--- P√°gina {pagina_num} ---\n{texto_pagina}\n"
            
            # Estrutura do resultado para PDF
            resultado = {
                'link': link_chamada,
                'tipo': 'PDF',
                'status_code': response.status_code,
                'tamanho_bytes': len(response.content),
                'total_paginas': total_paginas,
                'texto_extraido': texto_completo,
                'preview_texto': texto_completo[:500] + '...' if len(texto_completo) > 500 else texto_completo
            }
            
            print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Texto extra√≠do com sucesso!")
            print(f"   Tamanho do PDF: {len(response.content) / 1024:.2f} KB")
            print(f"   Total de p√°ginas: {total_paginas}")
            print(f"   Caracteres extra√≠dos: {len(texto_completo)}")
            
            return resultado
        
        else:
            # Se n√£o for PDF, processar como HTML
            print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Detectado conte√∫do HTML.")
            
            conteudo_html = response.text
            soup = BeautifulSoup(conteudo_html, 'html.parser')
            
            resultado = {
                'link': link_chamada,
                'tipo': 'HTML',
                'status_code': response.status_code,
                'tamanho_bytes': len(conteudo_html),
                'titulo_pagina': soup.title.string if soup.title else 'N/A',
                'html_completo': conteudo_html
            }
            
            print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Conte√∫do HTML capturado!")
            print(f"   Tamanho: {len(conteudo_html) / 1024:.2f} KB")
            print(f"   T√≠tulo: {resultado['titulo_pagina']}")
            
            return resultado
        
    except requests.exceptions.RequestException as e:
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ERRO na requisi√ß√£o: {e}")
        return {
            'link': link_chamada,
            'tipo': 'ERRO',
            'status_code': 0,
            'erro': str(e)
        }
    except Exception as e:
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ERRO ao processar conte√∫do: {e}")
        return {
            'link': link_chamada,
            'tipo': 'ERRO',
            'status_code': response.status_code if 'response' in locals() else 0,
            'erro': str(e)
        }


def main():
    """
    Fun√ß√£o principal
    """
    # Processar argumentos de linha de comando
    args = parse_args()
    
    # Configurar ChromaDB com base nos argumentos
    global USE_CHROMA, CHROMA_HOST, CHROMA_PORT
    use_chroma = args.chroma  # Usar vari√°vel local
    if args.chroma:
        USE_CHROMA = True
        CHROMA_HOST = args.chroma_host
        CHROMA_PORT = args.chroma_port
    
    print("=" * 80)
    print("RASPADOR DE CHAMADAS P√öBLICAS DO CNPq COM EXTRA√á√ÉO DE VARI√ÅVEIS")
    if use_chroma:
        print(f"Integra√ß√£o com OpenAI e ChromaDB ({CHROMA_HOST}:{CHROMA_PORT})")
    else:
        print("Integra√ß√£o com OpenAI (ChromaDB desativado)")
    print("=" * 80)
    print()
    
    # Verificar se a chave da API OpenAI est√° configurada
    if not OPENAI_API_KEY:
        print("‚ùå ERRO: OPENAI_API_KEY n√£o est√° configurada nas vari√°veis de ambiente.")
        print("   Por favor, configure a vari√°vel de ambiente OPENAI_API_KEY.")
        return None, None, None, None
    
    # Verificar conex√£o com ChromaDB apenas se estiver ativado
    if use_chroma:
        try:
            print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Verificando conex√£o com ChromaDB...")
            if chroma_client and collection:
                print(f"‚úÖ Conex√£o com ChromaDB j√° estabelecida anteriormente.")
            else:
                print(f"‚ùå ChromaDB n√£o inicializado corretamente.")
                print("   Continuando sem ChromaDB...")
                use_chroma = False
        except Exception as e:
            print(f"‚ùå ERRO ao verificar ChromaDB: {e}")
            print("   Continuando sem ChromaDB...")
            use_chroma = False
    
    # Executar raspagem
    dados_cnpq = raspar_cnpq()
    
    # Verificar se a raspagem foi bem-sucedida
    if dados_cnpq['metadata']['status'] != 'sucesso':
        print("‚ùå Erro durante a raspagem. Verifique os logs acima.")
        return dados_cnpq, [], [], []
    
    # Extrair links das chamadas
    links_chamadas = [chamada.get('link_chamada', '') for chamada in dados_cnpq.get('chamadas', [])]
    links_chamadas = [link for link in links_chamadas if link]  # Remover links vazios
    
    print(f"\n[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Total de links extra√≠dos: {len(links_chamadas)}")
    
    # Processar cada chamada
    resultados_chamadas = []
    variaveis_extraidas = []
    
    for idx, link in enumerate(links_chamadas, 1):
        print(f"\n[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Processando chamada {idx}/{len(links_chamadas)}")
        print(f"Link: {link}")
        
        # Buscar conte√∫do da chamada
        conteudo = buscar_conteudo_chamada(link)
        resultados_chamadas.append(conteudo)
        
        # Se for PDF, extrair vari√°veis usando LLM
        if conteudo and conteudo.get('tipo') == 'PDF':
            texto = conteudo.get('texto_extraido', '')
            print(f"\n[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Extraindo vari√°veis do PDF usando LLM...")
            
            try:
                vars_extraidas = extrair_variaveis_llm(texto, link)
                variaveis_extraidas.append({
                    'link': link,
                    'variaveis': vars_extraidas
                })
                print(f"‚úÖ Vari√°veis extra√≠das com sucesso para {link}")
            except Exception as e:
                print(f"‚ùå ERRO ao extrair vari√°veis: {e}")
                variaveis_extraidas.append({
                    'link': link,
                    'erro': str(e)
                })
    
    # Criar diret√≥rio para resultados
    Path("resultados").mkdir(exist_ok=True)
    
    # Salvar resultados em JSON
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Salvar dados da raspagem
    with open(f"resultados/cnpq_chamadas_{timestamp}.json", "w", encoding="utf-8") as f:
        json.dump(dados_cnpq, f, indent=2, ensure_ascii=False)
    
    # Salvar vari√°veis extra√≠das
    with open(f"resultados/variaveis_extraidas_{timestamp}.json", "w", encoding="utf-8") as f:
        json.dump(variaveis_extraidas, f, indent=2, ensure_ascii=False)
    
    print("\n" + "=" * 80)
    print(f"‚úÖ PROCESSAMENTO CONCLU√çDO!")
    print(f"üìä Estat√≠sticas:")
    print(f"   - Chamadas encontradas: {len(dados_cnpq.get('chamadas', []))}")
    print(f"   - Chamadas processadas: {len(resultados_chamadas)}")
    print(f"   - PDFs com vari√°veis extra√≠das: {len(variaveis_extraidas)}")
    print(f"\nüìÅ Resultados salvos em:")
    print(f"   - resultados/cnpq_chamadas_{timestamp}.json")
    print(f"   - resultados/variaveis_extraidas_{timestamp}.json")
    print("=" * 80)
    
    return dados_cnpq, links_chamadas, resultados_chamadas, variaveis_extraidas


if __name__ == "__main__":
    try:
        # Executar e capturar os retornos
        cnpq_chamadas, cnpq_links_extraidos, conteudos_chamadas, variaveis_extraidas = main()
        print("\n\n" + "=" * 80)
        print("\u2705 PROCESSAMENTO CONCLU√çDO COM SUCESSO!")
        print("=" * 80)
    except KeyboardInterrupt:
        print("\n\n" + "=" * 80)
        print("\u274c PROCESSAMENTO INTERROMPIDO PELO USU√ÅRIO")
        print("=" * 80)
    except Exception as e:
        print("\n\n" + "=" * 80)
        print(f"\u274c ERRO: {e}")
        print("=" * 80)
